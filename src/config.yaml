# Model Configuration
gemini_model: models/gemini-2.5-flash

groq:
  chat_model: openai/gpt-oss-120b

silicon_flow:
  embedding_model: Qwen/Qwen3-Embedding-8B
  reranker: Qwen/Qwen3-Reranker-8B
  


chunking:
  chunk_size: 1000
  chunk_overlap: 200
  separators: ["\n\n", "\n", " "]