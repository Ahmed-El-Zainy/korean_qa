import streamlit as st
import os
import sys
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from dotenv import load_dotenv
import requests
import json
import time

# Load environment variables
load_dotenv()
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


try:
    from logger.custom_logger import CustomLoggerTracker
    custom_log = CustomLoggerTracker()
    logger = custom_log.get_logger("rag_demo_standalone")

except ImportError:
    # Fallback to standard logging if custom logger not available
    logger = logging.getLogger("rag_demo_standalone")


@dataclass
class Document:
    """Document structure for RAG system."""
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[List[float]] = None

@dataclass
class RAGResult:
    """RAG query result."""
    query: str
    answer: str
    relevant_documents: List[Document]
    processing_time: float

class SimpleVectorStore:
    """Simple in-memory vector store for demonstration."""
    
    def __init__(self):
        self.documents: List[Document] = []
        self.embeddings: List[List[float]] = []
    
    def add_documents(self, documents: List[Document]):
        """Add documents to the vector store."""
        self.documents.extend(documents)
        for doc in documents:
            if doc.embedding:
                self.embeddings.append(doc.embedding)
    
    def similarity_search(self, query_embedding: List[float], top_k: int = 5) -> List[Document]:
        """Find most similar documents using cosine similarity."""
        if not self.embeddings or not query_embedding:
            return []
        
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            if doc_embedding:
                similarity = self._cosine_similarity(query_embedding, doc_embedding)
                similarities.append((similarity, self.documents[i]))
        
        # Sort by similarity and return top_k
        similarities.sort(key=lambda x: x[0], reverse=True)
        return [doc for _, doc in similarities[:top_k]]
    
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """Calculate cosine similarity between two vectors."""
        if len(a) != len(b):
            return 0.0
        
        dot_product = sum(x * y for x, y in zip(a, b))
        norm_a = sum(x * x for x in a) ** 0.5
        norm_b = sum(x * x for x in b) ** 0.5
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return dot_product / (norm_a * norm_b)

class EmbeddingSystem:
    """SiliconFlow API client for embeddings and chat completion."""
    
    def __init__(self, api_key: str, base_url: str = "https://api.siliconflow.cn/v1"):
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
    
    def generate_embeddings(self, texts: List[str], 
                          model: str = "BAAI/bge-large-zh-v1.5") -> List[List[float]]:
        """Generate embeddings for texts."""
        try:
            payload = {
                "model": model,
                "input": texts,
                "encoding_format": "float"
            }
            
            response = requests.post(
                f"{self.base_url}/embeddings",
                json=payload,
                headers=self.headers,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return [item['embedding'] for item in data.get('data', [])]
            else:
                logger.error(f"Embedding API error: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"Embedding generation failed: {e}")
            return []
    
    def rerank_documents(self, query: str, documents: List[str], 
                        model: str = "BAAI/bge-reranker-large",
                        top_k: int = 5) -> List[Dict]:
        """Rerank documents based on query relevance."""
        try:
            payload = {
                "model": model,
                "query": query,
                "documents": documents,
                "top_k": top_k,
                "return_documents": True
            }
            
            response = requests.post(
                f"{self.base_url}/rerank",
                json=payload,
                headers=self.headers,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get('results', [])
            else:
                logger.error(f"Rerank API error: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"Reranking failed: {e}")
            return []
    
    def chat_completion(self, messages: List[Dict[str, str]], 
                       model: str = "Qwen/Qwen2.5-7B-Instruct") -> str:
        """Generate chat completion."""
        try:
            payload = {
                "model": model,
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 1000
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers=self.headers,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                return data['choices'][0]['message']['content']
            else:
                logger.error(f"Chat completion API error: {response.status_code} - {response.text}")
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"Chat completion failed: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

class RAGSystem:
    """Complete RAG system using SiliconFlow."""
    
    def __init__(self, api_key: str):
        self.client = EmbeddingSystem(api_key)
        self.vector_store = SimpleVectorStore()
        logger.info("RAG System initialized")
    
    def add_documents(self, texts: List[str], metadatas: Optional[List[Dict]] = None):
        """Add documents to the RAG system."""
        if not metadatas:
            metadatas = [{"source": f"doc_{i}"} for i in range(len(texts))]
        
        logger.info(f"Adding {len(texts)} documents...")
        
        # Generate embeddings
        embeddings = self.client.generate_embeddings(texts)
        
        # Create document objects
        documents = []
        for i, (text, metadata) in enumerate(zip(texts, metadatas)):
            embedding = embeddings[i] if i < len(embeddings) else None
            doc = Document(content=text, metadata=metadata, embedding=embedding)
            documents.append(doc)
        
        # Add to vector store
        self.vector_store.add_documents(documents)
        logger.info(f"Successfully added {len(documents)} documents")
    
    def query(self, query: str, top_k: int = 5, use_reranking: bool = True) -> RAGResult:
        """Query the RAG system."""
        start_time = time.time()
        
        # Generate query embedding
        query_embeddings = self.client.generate_embeddings([query])
        query_embedding = query_embeddings[0] if query_embeddings else []
        
        if not query_embedding:
            logger.error("Failed to generate query embedding")
            return RAGResult(
                query=query,
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                relevant_documents=[],
                processing_time=time.time() - start_time
            )
        
        # Find similar documents
        similar_docs = self.vector_store.similarity_search(query_embedding, top_k * 2)
        
        if not similar_docs:
            return RAGResult(
                query=query,
                answer="ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                relevant_documents=[],
                processing_time=time.time() - start_time
            )
        
        # Optional reranking
        if use_reranking and len(similar_docs) > top_k:
            doc_texts = [doc.content for doc in similar_docs]
            rerank_results = self.client.rerank_documents(query, doc_texts, top_k=top_k)
            
            if rerank_results:
                # Reorder documents based on reranking
                reranked_docs = []
                for result in rerank_results:
                    doc_idx = result.get('index', 0)
                    if doc_idx < len(similar_docs):
                        reranked_docs.append(similar_docs[doc_idx])
                similar_docs = reranked_docs
        
        # Limit to top_k
        relevant_docs = similar_docs[:top_k]
        
        # Generate answer using context
        context = "\n\n".join([doc.content for doc in relevant_docs])
        answer = self._generate_answer(query, context)
        
        processing_time = time.time() - start_time
        
        return RAGResult(
            query=query,
            answer=answer,
            relevant_documents=relevant_docs,
            processing_time=processing_time
        )
    
    def _generate_answer(self, query: str, context: str) -> str:
        """Generate answer using context and query."""
        system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ì—†ìœ¼ë©´ 'ì£¼ì–´ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤'ë¼ê³  ë§í•´ì£¼ì„¸ìš”."""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {query}"}
        ]
        
        return self.client.chat_completion(messages)

# Sample Korean manufacturing data
SAMPLE_DOCUMENTS = [
    "TAB S10 ë„ì¥ ê³µì •ì˜ ìˆ˜ìœ¨ì€ í˜„ì¬ 95.2%ì…ë‹ˆë‹¤. ëª©í‘œ ìˆ˜ìœ¨ 94%ë¥¼ ìƒíšŒí•˜ê³  ìˆìœ¼ë©°, ì§€ë‚œë‹¬ ëŒ€ë¹„ 1.3% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë„ì¥ ë¼ì¸ì—ì„œ ë¶ˆëŸ‰ë¥ ì´ 4.8% ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë¶ˆëŸ‰ ì›ì¸ì€ ì˜¨ë„ í¸ì°¨(45%)ì™€ ìŠµë„ ë³€í™”(30%)ì…ë‹ˆë‹¤.",
    "S10 ëª¨ë¸ì˜ ì „ì²´ ìƒì‚° ìˆ˜ìœ¨ì€ 89.5%ë¡œ ëª©í‘œì¹˜ 88%ë¥¼ ìƒíšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì›”ê°„ ìƒì‚°ëŸ‰ì€ 15,000ëŒ€ì…ë‹ˆë‹¤.",
    "ë„ì¥ ë¼ì¸ì˜ ì˜¨ë„ëŠ” 22Â±2â„ƒ, ìŠµë„ëŠ” 45Â±5%ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ìë™ ì œì–´ ì‹œìŠ¤í…œìœ¼ë¡œ ê´€ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "í’ˆì§ˆê´€ë¦¬ ë¶€ì„œì—ì„œëŠ” ë§¤ì¼ 3íšŒ ìƒ˜í”Œë§ ê²€ì‚¬ë¥¼ ì‹¤ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²€ì‚¬ í•­ëª©ì€ ìƒ‰ìƒ, ê´‘íƒ, ë‘ê»˜ì…ë‹ˆë‹¤.",
    "ì˜ˆë°© ë³´ì „ ê³„íšì— ë”°ë¼ ë„ì¥ ì„¤ë¹„ëŠ” ì£¼ 1íšŒ ì •ê¸° ì ê²€ì„ ì‹¤ì‹œí•©ë‹ˆë‹¤. ë‹¤ìŒ ì •ê¸° ë³´ì „ì€ ë‹¤ìŒ ì£¼ í™”ìš”ì¼ì…ë‹ˆë‹¤.",
    "ì‹ ê·œ ë„ì¥ ì¬ë£Œ ì ìš© í›„ ì ‘ì°©ë ¥ì´ 15% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ìš©ì€ 10% ì¦ê°€í–ˆì§€ë§Œ í’ˆì§ˆ ê°œì„  íš¨ê³¼ê°€ í½ë‹ˆë‹¤.",
    "ì‘ì—…ì êµìœ¡ì€ ì›” 2íšŒ ì‹¤ì‹œë˜ë©°, ì•ˆì „êµìœ¡ê³¼ í’ˆì§ˆêµìœ¡ì„ í¬í•¨í•©ë‹ˆë‹¤. êµìœ¡ ì°¸ì„ë¥ ì€ 98.5%ì…ë‹ˆë‹¤."
]

def run_streamlit_app():
    """Run the Streamlit web application."""
    st.set_page_config(page_title="RAG Demo - Korean QA", page_icon="ğŸ¤–", layout="wide")
    
    st.title("ğŸ¤– Korean RAG Demo with SiliconFlow")
    st.markdown("*Retrieval-Augmented Generation for Korean Manufacturing Q&A*")
    
    # Sidebar configuration
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        api_key = st.text_input(
            "SiliconFlow API Key",
            value=os.getenv("SILICONFLOW_API_KEY", ""),
            type="password",
            help="Enter your SiliconFlow API key"
        )
        
        use_reranking = st.checkbox("Use Reranking", value=True, help="Use reranking for better results")
        top_k = st.slider("Top K Results", min_value=1, max_value=10, value=3)
        
        if st.button("Initialize RAG System"):
            if not api_key:
                st.error("Please provide SiliconFlow API key")
            else:
                with st.spinner("Initializing RAG system..."):
                    try:
                        rag_system = RAGSystem(api_key)
                        rag_system.add_documents(SAMPLE_DOCUMENTS)
                        st.session_state['rag_system'] = rag_system
                        st.success("RAG system initialized successfully!")
                    except Exception as e:
                        st.error(f"Failed to initialize RAG system: {e}")
    
    # Main interface
    if 'rag_system' in st.session_state:
        st.header("ğŸ’¬ Ask Questions")
        
        # Sample questions
        sample_questions = [
            "TAB S10 ë„ì¥ ê³µì • ìˆ˜ìœ¨ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë„ì¥ ë¼ì¸ì˜ ë¶ˆëŸ‰ë¥ ê³¼ ì£¼ìš” ì›ì¸ì€?",
            "í’ˆì§ˆ ê²€ì‚¬ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "ì˜ˆë°© ë³´ì „ ê³„íšì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        ]
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: TAB S10 ìˆ˜ìœ¨ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")
        
        with col2:
            st.markdown("**ìƒ˜í”Œ ì§ˆë¬¸:**")
            for i, sample in enumerate(sample_questions):
                if st.button(f"Q{i+1}", key=f"sample_{i}", help=sample):
                    st.rerun()
        
        if query:
            with st.spinner("Searching and generating answer..."):
                try:
                    result = st.session_state['rag_system'].query(
                        query, 
                        top_k=top_k, 
                        use_reranking=use_reranking
                    )
                    
                    # Display results
                    st.header("ğŸ“‹ Answer")
                    st.write(result.answer)
                    
                    st.header("ğŸ“„ Relevant Documents")
                    for i, doc in enumerate(result.relevant_documents):
                        with st.expander(f"Document {i+1} - {doc.metadata.get('source', 'Unknown')}"):
                            st.write(doc.content)
                    
                    # Stats
                    st.sidebar.metric("Processing Time", f"{result.processing_time:.2f}s")
                    st.sidebar.metric("Documents Found", len(result.relevant_documents))
                    
                except Exception as e:
                    st.error(f"Query failed: {e}")
    else:
        st.info("ğŸ‘ˆ Please initialize the RAG system using the sidebar")
        
        # Show sample documents
        st.header("ğŸ“š Sample Documents")
        st.markdown("The system includes these sample manufacturing documents:")
        for i, doc in enumerate(SAMPLE_DOCUMENTS, 1):
            st.markdown(f"**{i}.** {doc}")

def run_cli_demo():
    """Run command line interface demo."""
    print("ğŸ¤– Korean RAG Demo - CLI Mode")
    print("=" * 50)
    
    # Get API key
    api_key = os.getenv("SILICONFLOW_API_KEY")
    if not api_key:
        api_key = input("Enter your SiliconFlow API key: ")
    
    if not api_key:
        print("âŒ API key is required")
        return
    
    try:
        # Initialize RAG system
        print("ğŸ”„ Initializing RAG system...")
        rag_system = RAGSystem(api_key)
        rag_system.add_documents(SAMPLE_DOCUMENTS)
        print("âœ… RAG system ready!")
        
        # Interactive loop
        while True:
            print("\n" + "-" * 50)
            query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'quit'): ")
            
            if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                break
            
            if not query.strip():
                continue
            
            print("ğŸ” Searching...")
            result = rag_system.query(query, top_k=3, use_reranking=True)
            
            print(f"\nğŸ“‹ ë‹µë³€:")
            print(result.answer)
            
            print(f"\nğŸ“„ ê´€ë ¨ ë¬¸ì„œë“¤:")
            for i, doc in enumerate(result.relevant_documents, 1):
                print(f"{i}. {doc.content}")
            
            print(f"\nâ±ï¸  ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
    
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    # Check if running in streamlit context
    try:
        # This will raise an exception if not in streamlit context
        st.session_state
        run_streamlit_app()
    except:
        # Run CLI version
        run_cli_demo()